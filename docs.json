[{"name":"Nld","comment":" Natural Language Disambiguator - a flexible parser for loosely ordered token sequences.\n\n`Nld` parses sequences of tokens while:\n\n  - Ignoring irrelevant tokens\n  - Allowing tokens to appear in any order (preferring specified order)\n  - Lazily producing results in priority order\n\nUnlike traditional parser combinators, `Nld` is robust to reordering and\nalternate phrasings, making it ideal for parsing natural language input.\n\n\n# Running Parsers\n\n@docs Nld\n@docs run, runList, runTake\n\n\n# Token Matchers\n\n@docs word, words, token, nat, tokenMatching, minimalToken\n\n\n# Indexed Token Matchers\n\nThese return both the matched value and its position in the input.\n\n@docs indexedWord, indexedWords, indexedToken, indexedNat, indexedTokenMatching\n\n\n# Transforming and Combining\n\n@docs succeed, map, map2, map3, andThen, andMap\n@docs tuple2, tuple3\n\n\n# Alternatives and Repetition\n\n@docs choice, repeat\n\n\n# Autocompletion\n\n@docs autocomplete, topK\n\n","unions":[{"name":"Nld","comment":" An `Nld a` is a parser that produces values of type `a` from a sequence of tokens.\nIt explores multiple parse branches lazily, preferring matches where tokens appear\nin the specified order and closer together.\n","args":["a"],"cases":[]}],"aliases":[],"values":[{"name":"andMap","comment":" Apply a parser producing a function to a parser producing a value.\n\nThis enables pipe-style composition for building parsers with arbitrary arity:\n\n    runList\n        (succeed Tuple.pair\n            |> andMap (word \"buy\")\n            |> andMap nat\n        )\n        [ \"buy\", \"3\" ]\n        |> List.map Tuple.second\n    --> [ ( \"buy\", 3 ) ]\n\nWorks with any number of fields - no need for `map4`, `map5`, etc:\n\n    runList\n        (succeed (\\a b c -> { x = a, y = b, z = c })\n            |> andMap (word \"a\")\n            |> andMap (word \"b\")\n            |> andMap (word \"c\")\n        )\n        [ \"a\", \"b\", \"c\" ]\n        |> List.map Tuple.second\n    --> [ { x = \"a\", y = \"b\", z = \"c\" } ]\n\n","type":"Nld.Nld a -> Nld.Nld (a -> b) -> Nld.Nld b"},{"name":"andThen","comment":" Sequence two parsers. The second parser can depend on the result of the first.\n","type":"(a -> Nld.Nld b) -> Nld.Nld a -> Nld.Nld b"},{"name":"autocomplete","comment":" Get autocomplete suggestions as a Peach.\n\nThis walks the parse tree, collecting suggestions at every point where\nthe parser fails due to missing tokens. The result is a lazy stream\nof suggestion sets, ordered by parse weight.\n\n","type":"Nld.Nld a -> Nld.TokenPositions -> Peach.Peach (Set.Set String.String)"},{"name":"choice","comment":" Try multiple parsers and return all successful parses.\n\n    runList (choice [ word \"delete\", word \"add\" ]) [ \"delete\" ]\n        |> List.map Tuple.second\n    --> [ \"delete\" ]\n\n","type":"List.List (Nld.Nld a) -> Nld.Nld a"},{"name":"indexedNat","comment":" Match a natural number and return it with its position.\n","type":"Nld.Nld ( Basics.Int, Basics.Int )"},{"name":"indexedToken","comment":" Match any token and return it with its position.\n","type":"Nld.Nld ( String.String, Basics.Int )"},{"name":"indexedTokenMatching","comment":" Match tokens satisfying a predicate and return with position.\n","type":"(String.String -> Basics.Bool) -> Nld.Nld ( String.String, Basics.Int )"},{"name":"indexedWord","comment":" Match a specific word and return both the word and its position.\n\n    runList (indexedWord \"cat\") [ \"the\", \"cat\", \"sat\" ]\n    --> [ ( 2, ( \"cat\", 1 ) ) ]\n\n","type":"String.String -> Nld.Nld ( String.String, Basics.Int )"},{"name":"indexedWords","comment":" Match any of the given words and return the matched word with its position.\n","type":"List.List String.String -> Nld.Nld ( String.String, Basics.Int )"},{"name":"map","comment":" Transform the result of a parser.\n\n    runList (map String.toUpper (word \"hello\")) [ \"hello\" ]\n    --> [ ( 1, \"HELLO\" ) ]\n\n","type":"(a -> b) -> Nld.Nld a -> Nld.Nld b"},{"name":"map2","comment":" Combine two parsers.\n","type":"(a -> b -> c) -> Nld.Nld a -> Nld.Nld b -> Nld.Nld c"},{"name":"map3","comment":" Combine three parsers.\n","type":"(a -> b -> c -> d) -> Nld.Nld a -> Nld.Nld b -> Nld.Nld c -> Nld.Nld d"},{"name":"minimalToken","comment":" Match any of several weighted tokens. Lower weights are preferred.\n\n    runTake 1 (minimalToken [ ( 0.0, \"delete\" ), ( 1.0, \"remove\" ) ]) [ \"remove\", \"delete\" ]\n        |> List.map Tuple.second\n    --> [ \"delete\" ]\n\n","type":"List.List ( Basics.Float, String.String ) -> Nld.Nld String.String"},{"name":"nat","comment":" Match a natural number (non-negative integer).\n\n    runList (tuple2 (word \"buy\") nat) [ \"buy\", \"3\", \"apples\" ]\n        |> List.map Tuple.second\n    --> [ ( \"buy\", 3 ) ]\n\n","type":"Nld.Nld Basics.Int"},{"name":"repeat","comment":" Match zero or more occurrences of a parser.\n\nResults include all possible match lengths, with longer matches preferred.\n\n","type":"Nld.Nld a -> Nld.Nld (List.List a)"},{"name":"run","comment":" Run a parser on TokenPositions and return all results.\n","type":"Nld.Nld a -> Nld.TokenPositions -> List.List ( Basics.Float, a )"},{"name":"runList","comment":" Run a parser on a list of tokens and return all results as weighted pairs.\nResults are ordered by weight (best matches first).\n\n    runList (word \"hello\") [ \"hello\", \"world\" ]\n        |> List.map Tuple.second\n    --> [ \"hello\" ]\n\n    runList (tuple2 (word \"delete\") (word \"file\")) [ \"file\", \"delete\" ]\n        |> List.map Tuple.second\n    --> [ ( \"delete\", \"file\" ) ]\n\n","type":"Nld.Nld a -> List.List String.String -> List.List ( Basics.Float, a )"},{"name":"runTake","comment":" Run a parser and take only the first n results.\n\n    runTake 1 (word \"cat\") [ \"the\", \"cat\", \"sat\" ]\n    --> [ ( 2, \"cat\" ) ]\n\n","type":"Basics.Int -> Nld.Nld a -> List.List String.String -> List.List ( Basics.Float, a )"},{"name":"succeed","comment":" A parser that always succeeds with the given value without consuming any tokens.\n\nThis is the fundamental building block for applicative-style parsing with `andMap`.\n\n    runList (succeed 42) [ \"any\", \"tokens\" ]\n        |> List.map Tuple.second\n    --> [ 42 ]\n\n    -- Use with choice for default values:\n    runList (choice [ nat, succeed 1 ]) [ \"not-a-number\" ]\n        |> List.map Tuple.second\n    --> [ 1 ]\n\n","type":"a -> Nld.Nld a"},{"name":"token","comment":" Match any token and return it.\n\n    runTake 1 token [ \"anything\" ]\n        |> List.map Tuple.second\n    --> [ \"anything\" ]\n\n","type":"Nld.Nld String.String"},{"name":"tokenMatching","comment":" Match tokens satisfying a predicate.\n\n    runList (tokenMatching (String.endsWith \".txt\")) [ \"open\", \"report.txt\" ]\n        |> List.map Tuple.second\n    --> [ \"report.txt\" ]\n\n","type":"(String.String -> Basics.Bool) -> Nld.Nld String.String"},{"name":"topK","comment":" Get autocomplete suggestions for incomplete input.\nReturns a list of sets of tokens that could complete the parse.\n\n    topK 5 (word \"buy\") []\n    -- Returns [ Set.fromList [ \"buy\" ] ]\n\n    topK 5 (tuple2 (word \"buy\") (word \"apples\")) [ \"buy\" ]\n    -- Returns [ Set.fromList [ \"apples\" ] ]\n\nThis explores the parse tree lazily, finding all points where the parser\nneeds tokens that aren't present in the input.\n\n","type":"Basics.Int -> Nld.Nld a -> List.List String.String -> List.List (Set.Set String.String)"},{"name":"tuple2","comment":" Combine two parsers into a tuple.\n\n    runList (tuple2 (word \"delete\") (word \"file\")) [ \"delete\", \"file\" ]\n        |> List.map Tuple.second\n    --> [ ( \"delete\", \"file\" ) ]\n\n","type":"Nld.Nld a -> Nld.Nld b -> Nld.Nld ( a, b )"},{"name":"tuple3","comment":" Combine three parsers into a tuple.\n","type":"Nld.Nld a -> Nld.Nld b -> Nld.Nld c -> Nld.Nld ( a, b, c )"},{"name":"word","comment":" Match a specific word/token.\n\n    runList (word \"delete\") [ \"please\", \"delete\", \"this\" ]\n    --> [ ( 2, \"delete\" ) ]\n\n","type":"String.String -> Nld.Nld String.String"},{"name":"words","comment":" Match any of the given words, preferring earlier ones in the list.\nUseful for synonyms.\n\n    runList (words [ \"delete\", \"remove\", \"erase\" ]) [ \"please\", \"erase\", \"this\" ]\n        |> List.map Tuple.second\n    --> [ \"delete\" ]\n\nThe result is canonicalized to the first word in the list.\n\n","type":"List.List String.String -> Nld.Nld String.String"}],"binops":[]},{"name":"Peach","comment":" A lazy priority search data structure, ported from Unison's `pchiusano/peachy` library.\n\n`Peach` is similar to `Each` but expands branches with smaller weights first.\nIt allows you to explore multiple possibilities, prioritizing by weight.\n\n\n# Core Types\n\n@docs Peach\n\n\n# Primitive Operations\n\n@docs peach, fail, succeed, lazy\n\n\n# Combinators\n\n@docs map, flatMap, choose\n\n\n# Extractors\n\n@docs head, toList, take\n\n\n# Convenience Functions\n\n@docs rankBy, each, optional\n\n","unions":[{"name":"Peach","comment":" A `Peach a` represents a lazy priority search computation that can yield\nmultiple weighted results. Results with smaller weights are explored first.\n\nInternally, this is represented as a priority queue of either:\n\n  - Concrete weighted values\n  - Thunks that produce more `Peach` elements when forced\n\nThis allows lazy evaluation: results are only computed when extracted.\n\n","args":["a"],"cases":[]}],"aliases":[],"values":[{"name":"choose","comment":" Choose between multiple `Peach` computations, exploring them in priority order.\n\n    choose\n        [ peach [ ( 1.0, \"a\" ) ]\n        , peach [ ( 2.0, \"b\" ) ]\n        , peach [ ( 0.5, \"c\" ) ]\n        ]\n        |> toList\n    --> [ ( 0.5, \"c\" ), ( 1.0, \"a\" ), ( 2.0, \"b\" ) ]\n\n","type":"List.List (Peach.Peach a) -> Peach.Peach a"},{"name":"each","comment":" Create a `Peach` from a list, treating each element equally (weight 0).\n\n    each [ \"a\", \"b\", \"c\" ]\n        |> toList\n        |> List.length\n    --> 3\n\n","type":"List.List a -> Peach.Peach a"},{"name":"fail","comment":" A `Peach` that yields no results (represents failure).\n\n    fail\n        |> head\n    --> Nothing\n\n","type":"Peach.Peach a"},{"name":"flatMap","comment":" Chain computations where the second depends on the result of the first.\nThe weights are combined additively.\n\n    peach [ ( 1.0, \"a\" ), ( 2.0, \"b\" ) ]\n        |> flatMap (\\x -> peach [ ( 0.5, x ++ \"1\" ), ( 1.0, x ++ \"2\" ) ])\n        |> take 4\n    --> [ ( 1.5, \"a1\" ), ( 2.0, \"a2\" ), ( 2.5, \"b1\" ), ( 3.0, \"b2\" ) ]\n\n**Laziness:** `flatMap` is lazy - it doesn't immediately evaluate all branches.\nInstead, it creates thunks that are evaluated on-demand as results are extracted.\n\n","type":"(a -> Peach.Peach b) -> Peach.Peach a -> Peach.Peach b"},{"name":"head","comment":" Get the first (lowest weight) result from a `Peach` computation, if any.\n\nThis forces evaluation of thunks as needed to find the minimum-weight value.\n\n    peach [ ( 2.0, \"b\" ), ( 1.0, \"a\" ) ]\n        |> head\n    --> Just ( 1.0, \"a\" )\n\n    fail\n        |> head\n    --> Nothing\n\n","type":"Peach.Peach a -> Maybe.Maybe ( Basics.Float, a )"},{"name":"lazy","comment":" Create a lazy `Peach` from a thunk. The thunk will only be evaluated\nwhen results are extracted. This is the key primitive for lazy evaluation.\n\n    lazy 0.0 (\\() -> peach [ ( 1.0, \"computed\" ) ])\n        |> head\n    --> Just ( 1.0, \"computed\" )\n\nThe first argument is the minimum possible weight of results from this thunk.\nThis is used for priority ordering - thunks with lower weights are forced first.\n\n","type":"Basics.Float -> (() -> Peach.Peach a) -> Peach.Peach a"},{"name":"map","comment":" Transform the values in a `Peach` computation.\n\n    peach [ ( 1.0, 2 ), ( 2.0, 3 ) ]\n        |> map (\\x -> x * 2)\n        |> toList\n    --> [ ( 1.0, 4 ), ( 2.0, 6 ) ]\n\nNote: `map` is lazy - it wraps transformations in thunks for deferred items.\n\n","type":"(a -> b) -> Peach.Peach a -> Peach.Peach b"},{"name":"optional","comment":" Convert an `Optional` value to a `Peach`.\n\n    optional (Just \"hello\")\n        |> head\n    --> Just ( 0.0, \"hello\" )\n\n    optional Nothing\n        |> head\n    --> Nothing\n\n","type":"Maybe.Maybe a -> Peach.Peach a"},{"name":"peach","comment":" Create a `Peach` from a list of weighted values. The values will be explored\nin order of increasing weight (smallest first).\n\n    peach [ ( 2.0, \"b\" ), ( 1.0, \"a\" ), ( 3.0, \"c\" ) ]\n        |> head\n    --> Just ( 1.0, \"a\" )\n\n","type":"List.List ( Basics.Float, a ) -> Peach.Peach a"},{"name":"rankBy","comment":" Rank values by a function and create a `Peach` from them.\n\n    rankBy (\\s -> toFloat (String.length s)) [ \"apple\", \"kiwi\", \"banana\" ]\n        |> head\n    --> Just ( 4.0, \"kiwi\" )\n\n","type":"(a -> Basics.Float) -> List.List a -> Peach.Peach a"},{"name":"succeed","comment":" A `Peach` that yields exactly one result with weight 0.\n\n    succeed \"hello\"\n        |> head\n    --> Just ( 0.0, \"hello\" )\n\n","type":"a -> Peach.Peach a"},{"name":"take","comment":" Take the first `n` results from a `Peach` computation, ordered by weight.\n\nThis is the primary way to extract results lazily. Only the minimum number\nof thunks needed to produce `n` results will be evaluated.\n\n    peach [ ( 2.0, \"b\" ), ( 1.0, \"a\" ), ( 3.0, \"c\" ) ]\n        |> take 2\n    --> [ ( 1.0, \"a\" ), ( 2.0, \"b\" ) ]\n\n","type":"Basics.Int -> Peach.Peach a -> List.List ( Basics.Float, a )"},{"name":"toList","comment":" Convert a `Peach` computation to a list of all results, ordered by weight (smallest first).\n\n**Warning:** This forces evaluation of all thunks. For infinite or very large\nsearch spaces, use `take` instead.\n\n    peach [ ( 2.0, \"b\" ), ( 1.0, \"a\" ), ( 3.0, \"c\" ) ]\n        |> toList\n    --> [ ( 1.0, \"a\" ), ( 2.0, \"b\" ), ( 3.0, \"c\" ) ]\n\n","type":"Peach.Peach a -> List.List ( Basics.Float, a )"}],"binops":[]}]